{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully cleaned and saved to 'FA_Data_Cleaned.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# This simulates loading your data.\n",
    "# In your real code, you would use: df = pd.read_csv(\"your_file.csv\")\n",
    "data = {\n",
    "    'วันครบอายุเห็นชอบ': [\n",
    "        '2/6/2562', '4/19/2562', '2/6/2562', '___', '5/20/2562', '6/10/2562',\n",
    "        '6/24/2562', '8/3/2562', '9/1/2562', '9/4/2562', '11/4/2562', '10/19/2562',\n",
    "        '9/24/2562', '11/29/2562', '11/27/2562', '12/7/2562', '3/30/2563', '4/7/2563',\n",
    "        '5/1/2563', '4/20/2563', '4/17/2563', '5/5/2563', '5/24/2563', '7/14/2563',\n",
    "        '6/5/2563', '7/6/2563', 'nan', '8/10/2563', '9/4/2563', '8/10/2563', 'nan',\n",
    "        '10/10/2563', '9/30/2563', '12/9/2563', '1/11/2564', '1/20/2564', '2/14/2564',\n",
    "        '2/27/2564', '4/4/2564', '3/3/2564', '4/21/2564', '5/17/2564', '5/22/2564',\n",
    "        '5/17/2564', '7/11/2564', '10/7/2564', '11/26/2564', '3/30/2564', '1/26/2565',\n",
    "        '20/03/65', '25/03/65', '29/03/65', '3/5/2565', '6/6/2565', 'รายใหม่',\n",
    "        '11/6/2565', '18/07/2565', '26/07/2565', '7/8/2565', '-', '24/09/2565',\n",
    "        '30/09/2565', '30/11/2565', '26/12/2565', '08/02/2561 - 07/02/2566',\n",
    "        '13/06/2561 - 12/06/2566', '25/06/2561 - 24/06/2566', '19/07/2561 - 18/07/2566',\n",
    "        '24/07/2561 - 23/07/2566', 'nan', '24/08/2561 - 23/08/2566', '03/09/2561 - 02/09/2566',\n",
    "        '28/09/2561 - 27/09/2566', '21/10/2561 - 20/10/2566', '03/12/2561 - 02/12/2566',\n",
    "        '22/12/2561 - 21/12/2566', 'nan', '20/04/2562 - 19/04/2567', '16/05/2562 - 15/05/2567',\n",
    "        '06/06/2562 - 05/06/2567', '21/05/2562 - 20/05/2567', 'nan', '30/07/2562 - 29/07/2567',\n",
    "        '02/09/2562 - 01/09/2567', 'nan', '05/09/2562 - 04/09/2567', '20/10/2562 - 19/10/2567',\n",
    "        '31/10/2562 - 30/10/2567', '30/11/2562 - 29/11/2567', '12/12/2562 - 11/12/2567',\n",
    "        'nan', '06/02/2563 - 05/02/2568', '31/03/2563 - 30/03/2568', '22/04/2563 - 21/04/2568',\n",
    "        '08/04/2563 - 07/04/2568', 'nan', '06/05/2563 - 05/05/2568', 'nan', 'nan',\n",
    "        '31/07/2563 - 30/07/2568', '02/07/2563 - 01/07/2568', 'nan', 'nan', 'nan', 'nan',\n",
    "        'nan', 'nan', 'nan', 'nan', 'nan'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def clean_and_split_dates_to_ad(df, col_name='วันครบอายุเห็นชอบ'):\n",
    "    s = df[col_name].astype(str).str.strip()\n",
    "    mask = s.str.contains(' - ', na=False)\n",
    "    \n",
    "    split_data = s[mask].str.split(' - ', n=1, expand=True)\n",
    "    \n",
    "    df['วันที่อนุญาต'] = pd.Series(dtype='object')\n",
    "    if not split_data.empty:\n",
    "        df.loc[mask, 'วันที่อนุญาต'] = split_data[0]\n",
    "        df.loc[mask, col_name] = split_data[1]\n",
    "\n",
    "    def convert_thai_dates_to_ad(series):\n",
    "        dates = series.astype(str).str.strip().replace(['___', '-', 'nan', 'รายใหม่'], np.nan)\n",
    "        clean_dates = dates.dropna()\n",
    "        \n",
    "        if clean_dates.empty:\n",
    "            return pd.Series(pd.NaT, index=series.index)\n",
    "            \n",
    "        parts = clean_dates.str.split('/', expand=True)\n",
    "        year = pd.to_numeric(parts[parts.columns[-1]], errors='coerce')\n",
    "        ad_year = np.where(year < 100, year + 2500, year) - 543\n",
    "        \n",
    "        temp_df = pd.DataFrame({\n",
    "            'year': ad_year,\n",
    "            'month': pd.to_numeric(parts[1], errors='coerce'),\n",
    "            'day': pd.to_numeric(parts[0], errors='coerce')\n",
    "        })\n",
    "        \n",
    "        converted_dates = pd.to_datetime(temp_df, errors='coerce')\n",
    "        return converted_dates.reindex(series.index)\n",
    "\n",
    "    df['วันที่อนุญาต'] = convert_thai_dates_to_ad(df['วันที่อนุญาต'])\n",
    "    df[col_name] = convert_thai_dates_to_ad(df[col_name])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def convert_ad_to_be_str(ad_date_series):\n",
    "    # This function converts a pandas Series of AD datetime objects to BE date strings\n",
    "    be_series = ad_date_series.copy()\n",
    "    valid_dates_mask = be_series.notna()\n",
    "    \n",
    "    # Apply conversion only on valid (non-NaT) dates\n",
    "    be_series.loc[valid_dates_mask] = (\n",
    "        be_series.loc[valid_dates_mask] + pd.DateOffset(years=543)\n",
    "    ).dt.strftime('%d/%m/%Y')\n",
    "    \n",
    "    return be_series\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "# 1. Clean data and convert dates to AD for processing\n",
    "df_processed = clean_and_split_dates_to_ad(df.copy())\n",
    "\n",
    "# 2. Create a new DataFrame for export\n",
    "df_for_export = df_processed.copy()\n",
    "\n",
    "# 3. Convert date columns back to BE format for the export file\n",
    "df_for_export['วันที่อนุญาต'] = convert_ad_to_be_str(df_for_export['วันที่อนุญาต'])\n",
    "df_for_export['วันครบอายุเห็นชอบ'] = convert_ad_to_be_str(df_for_export['วันครบอายุเห็นชอบ'])\n",
    "\n",
    "# 4. Define the output filename\n",
    "output_filename = \"FA_Data_Cleaned_BE.xlsx\"\n",
    "\n",
    "# 5. Save the final DataFrame (with BE dates) to an Excel file\n",
    "df_for_export.to_excel(\n",
    "    output_filename,\n",
    "    sheet_name='Cleaned Data (BE)',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"Data successfully cleaned and saved to '{output_filename}' with dates in BE format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1043d525",
   "metadata": {},
   "source": [
    "### FA-2 Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49959859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"Dataset\\FA-2 (ปี 2565).xlsm\"\n",
    "output_file = \"FA-2 Sheet.xlsx\"\n",
    "\n",
    "data = pd.read_excel(input_file, dtype=str)\n",
    "\n",
    "p_columns = [\"รายใหม่\", \"ต่ออายุ\"]\n",
    "is_p_or_1 = data[p_columns].isin([\"P\", \"1\"])\n",
    "mask = is_p_or_1.any(axis=1)\n",
    "\n",
    "data.loc[mask, 'ประเภทคำขอ'] = is_p_or_1[mask].idxmax(axis=1)\n",
    "\n",
    "data.to_excel(\n",
    "    output_file,\n",
    "    sheet_name='Processed_Data',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45f6ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kongl\\AppData\\Local\\Temp\\ipykernel_22724\\774214242.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['สถิติ'] = pd.to_datetime(df[\"วันที่ยื่นคำขอ\"], errors='coerce').dt.quarter.apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_file = \"Dataset\\FA-2 (ปี 2565).xlsm\"\n",
    "output_file = \"FA-2_Processed.xlsx\"\n",
    "\n",
    "df = pd.read_excel(input_file, dtype=str)\n",
    "\n",
    "df['สถิติ'] = pd.to_datetime(df[\"วันที่ยื่นคำขอ\"], errors='coerce').dt.quarter.apply(\n",
    "    lambda q: f'Quarter {int(q)}' if pd.notna(q) else ''\n",
    ")\n",
    "\n",
    "app_type_cols = df.columns.intersection([\"รายใหม่\", \"ต่ออายุ\"])\n",
    "if not app_type_cols.empty:\n",
    "    is_p_or_1 = df[app_type_cols].isin([\"P\", \"1\"])\n",
    "    mask = is_p_or_1.any(axis=1)\n",
    "    df.loc[mask, 'ประเภทคำขอ'] = is_p_or_1[mask].idxmax(axis=1)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "try:\n",
    "    # Find insertion point after the column containing 'FA-2'\n",
    "    ref_col_index = next(i for i, col in enumerate(cols) if 'FA-2' in col)\n",
    "    # Move 'สถิติ' column to the correct position\n",
    "    cols.insert(ref_col_index + 1, cols.pop(cols.index('สถิติ')))\n",
    "    df = df[cols]\n",
    "except (StopIteration, ValueError):\n",
    "    # If reference column isn't found, the order remains as is\n",
    "    pass\n",
    "\n",
    "df.to_excel(output_file, sheet_name='Processed_Data', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8caefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15226061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ประมวลผลเสร็จสิ้น บันทึกไฟล์ที่: Dataset\\FA-2 Sheet_classified_llm_final.xlsx\n",
      "\n",
      "ตัวอย่างผลลัพธ์:\n",
      "                       ชื่อบริษัท FA  คำนำหน้า\n",
      "0                    เคที ซีมิโก้ บล.       บล\n",
      "1       เมอร์ชั่น พาร์ทเนอร์ บล. บมจ.       บล\n",
      "2              แอพเพิล เวลธ์ บล. บมจ.       บล\n",
      "3              เพลินจิต แคปปิตอล บจก.      บจก\n",
      "4             เวลแคป แอดไวเซอรี่ บจก.      บจก\n",
      "5             เอส 14 แอดไวเซอรี่ บจก.      บจก\n",
      "6                     เออีซี บล. บมจ.       บล\n",
      "7            ออพท์เอเชีย แคปิตอล บจก.      บจก\n",
      "8        หยวนต้า (ประเทศไทย) บล. บมจ.       บล\n",
      "9        หยวนต้า (ประเทศไทย) บล. บมจ.       บล\n",
      "10                  โกลเบล็ก บล. บจก.       บล\n",
      "11                    กรุงไทย ธ. บมจ.   ธนาคาร\n",
      "12        แอสเซท โปร แมเนจเม้นท์ บจก.      บจก\n",
      "13  แคปปิตอล ลิ้งค์ แอ๊ดไวเซอรี่ บจก.      บจก\n",
      "14         ที่ปรึกษา เอเชีย พลัส บจก.      บจก\n",
      "15  แคปปิตอล ลิ้งค์ แอ๊ดไวเซอรี่ บจก.      บจก\n",
      "16        เคทีบี (ประเทศไทย) บล. บมจ.       บล\n",
      "17                    กรุงเทพ ธ. บมจ.   ธนาคาร\n",
      "18           สยาม อัลฟา แคปปิตอล บจก.      บจก\n",
      "19                   เซจแคปปิตอล บจก.      บจก\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import random\n",
    "\n",
    "API_KEY = \"sk-GqA4Uj6iZXaykbOzIlFGtmdJr6VqiX94NhhjPZaf81kylRzh\"\n",
    "BASE_URL = \"https://api.opentyphoon.ai/v1\"\n",
    "MODEL = \"typhoon-v2.1-12b-instruct\"\n",
    "FILE_PATH = \"Dataset\\FA-2 Sheet.xlsx\"\n",
    "OUTPUT_FILE_PATH = \"Dataset\\FA-2 Sheet_classified_llm_final.xlsx\"\n",
    "COMPANY_COLUMN = 'ชื่อบริษัท FA '\n",
    "PREFIX_COLUMN = 'คำนำหน้า'\n",
    "VALID_TYPES = {'บจก', 'บล', 'ธนาคาร', 'บลจ'}\n",
    "SYSTEM_PROMPT = (\n",
    "    \"คุณคือ AI ผู้เชี่ยวชาญการจำแนกประเภทบริษัทในไทย \"\n",
    "    \"ให้ตอบกลับมาเพียงคำเดียวจากตัวเลือกนี้: 'บจก.', 'บล.', 'ธนาคาร', 'บลจ.' \"\n",
    "    \"ถ้าไม่เข้าข่าย ให้ตอบ 'Unknown'\"\n",
    ")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "\n",
    "def classify(company_name):\n",
    "    if pd.isna(company_name):\n",
    "        return \"\"\n",
    "    for i in range(5):\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": f\"'{company_name}'\"}\n",
    "            ],\n",
    "            max_tokens=10,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        result = response.choices[0].message.content.strip().replace('.', '')\n",
    "        if result in VALID_TYPES:\n",
    "            return result\n",
    "        if i < 4:\n",
    "            time.sleep((2 ** i) + random.uniform(0, 1))\n",
    "    return \"Unknown\"\n",
    "\n",
    "df = pd.read_excel(FILE_PATH)\n",
    "\n",
    "if PREFIX_COLUMN not in df.columns:\n",
    "    df[PREFIX_COLUMN] = \"\"\n",
    "\n",
    "names = df[COMPANY_COLUMN].dropna().unique().tolist()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    results = list(executor.map(classify, names))\n",
    "\n",
    "mapping = dict(zip(names, results))\n",
    "df[PREFIX_COLUMN] = df[COMPANY_COLUMN].map(mapping).fillna('')\n",
    "df.to_excel(OUTPUT_FILE_PATH, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
